{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import scipy\n",
    "import numpy.ma as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [1, 5, 10, 20, 30, 40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_prefix = './Datasets/APS/Q1/'\n",
    "APS_guest_full_test = pd.read_csv(dataset_path_prefix +  'APS_guest_full_test.csv', na_values = 'na', index_col = 'info')\n",
    "APS_guest_full_train = pd.read_csv(dataset_path_prefix +  'APS_guest_full_train.csv', na_values = 'na', index_col = 'info')\n",
    "APS_host_full_test = pd.read_csv(dataset_path_prefix +  'APS_host_full_test.csv', na_values = 'na', index_col = 'info')\n",
    "APS_host_full_train = pd.read_csv(dataset_path_prefix +  'APS_host_full_train.csv', na_values = 'na', index_col = 'info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "assert(len(APS_guest_full_test) == len(APS_host_full_test))\n",
    "assert(len(APS_guest_full_train) == len(APS_host_full_train))\n",
    "assert(len(APS_guest_full_test.columns) == len(APS_host_full_test.columns)+1)\n",
    "assert(len(APS_guest_full_train.columns) == len(APS_host_full_train.columns)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n"
     ]
    }
   ],
   "source": [
    "APS_train_df = pd.concat([APS_guest_full_train, APS_host_full_train], axis = 1)\n",
    "APS_test_df = pd.concat([APS_guest_full_test, APS_host_full_test], axis = 1)\n",
    "print(len(APS_train_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coefficient of variance (statistic_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cv_dfs(df, n_features):\n",
    "    cv_res = scipy.stats.variation(df, nan_policy = 'omit')\n",
    "    cv_res = ma.getdata(cv_res).tolist()\n",
    "    \n",
    "    # remove the columns that coeficient of variance is 0\n",
    "    to_rm = []\n",
    "    for idx in range(len(cv_res)):\n",
    "        if (cv_res[idx] == 0):\n",
    "            to_rm.insert(0, idx)\n",
    "    for idx in to_rm:\n",
    "        print('removing column ' + str(idx) + ', because of 0 cv value')\n",
    "        cv_res.pop(idx)\n",
    "        APS_train_df_no_y.drop(APS_train_df_no_y.columns[idx] ,1)\n",
    "        \n",
    "    res = []\n",
    "    # select features with n smallest cv value (larget than 0)\n",
    "    for n_feature in n_features:\n",
    "        smallest_idx = sorted(range(len(cv_res)), key=lambda k: cv_res[k])[:n_feature]\n",
    "        print(smallest_idx)\n",
    "        tmp = df.iloc[:, smallest_idx]\n",
    "        print('df', len(tmp.columns), len(tmp))\n",
    "        res.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing column 89, because of 0 cv value\n",
      "[78]\n",
      "df 1 6000\n",
      "[78, 77, 87, 76, 71]\n",
      "df 5 6000\n",
      "[78, 77, 87, 76, 71, 75, 86, 74, 72, 73]\n",
      "df 10 6000\n",
      "[78, 77, 87, 76, 71, 75, 86, 74, 72, 73, 79, 112, 119, 130, 143, 124, 142, 118, 147, 2]\n",
      "df 20 6000\n",
      "[78, 77, 87, 76, 71, 75, 86, 74, 72, 73, 79, 112, 119, 130, 143, 124, 142, 118, 147, 2, 89, 22, 23, 146, 67, 16, 156, 62, 82, 110]\n",
      "df 30 6000\n",
      "[78, 77, 87, 76, 71, 75, 86, 74, 72, 73, 79, 112, 119, 130, 143, 124, 142, 118, 147, 2, 89, 22, 23, 146, 67, 16, 156, 62, 82, 110, 81, 103, 93, 12, 80, 0, 117, 159, 53, 84]\n",
      "df 40 6000\n"
     ]
    }
   ],
   "source": [
    "APS_train_df_no_y = APS_train_df.drop('class', 1)\n",
    "APS_train_y = APS_train_df['class']\n",
    "create_cv_dfs(APS_train_df_no_y, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
